# -*- coding: utf-8 -*-
"""Project_20223_(256x256)-checkpoint.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y6BxQED8ZPFh7vlTBQf1I6_iGWR2uFwx
"""

from google.colab import drive
drive.mount('/content/drive')

"""#Import libraries"""

from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Concatenate, Input, UpSampling2D, Lambda
from tensorflow.keras.models import Model, load_model
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.preprocessing import image
from PIL import Image
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow.keras.preprocessing import image
from sklearn.model_selection import train_test_split

"""#Functions

# khung hình
"""

INPUT_WIDTH = 256
INPUT_HEIGHT = 256
INPUT_CHANNELS = 1

#Mạng Unet
def down_block(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(x)
    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(c)
    p = MaxPool2D((2, 2), (2, 2))(c)
    return c, p

def up_block(x, skip, filters, kernel_size=(3, 3), padding="same", strides=1):
    us = UpSampling2D((2, 2))(x)
    concat = Concatenate()([us, skip])
    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(concat)
    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(c)
    return c

def bottleneck(x, filters, kernel_size=(3, 3), padding="same", strides=1):
    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(x)
    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation="relu")(c)
    return c



def UNet():
    f = [64, 128, 256, 512, 1024]
    inputs = Input((INPUT_HEIGHT, INPUT_WIDTH, INPUT_CHANNELS))
    p0 = inputs
    c1, p1 = down_block(p0, f[0])
    c2, p2 = down_block(p1, f[1])
    c3, p3 = down_block(p2, f[2])
    c4, p4 = down_block(p3, f[3])

    bn = bottleneck(p4, f[4])

    u1 = up_block(bn, c4, f[3])
    u2 = up_block(u1, c3, f[2])
    u3 = up_block(u2, c2, f[1])
    u4 = up_block(u3, c1, f[0])

    outputs = Conv2D(1, (1, 1), padding="same", activation="sigmoid")(u4)
    model = Model(inputs, outputs)
    return model


#Show ảnh và mask
def plot_image_and_mask(image, mask, img_name):
    '''
    Function to plot a single prediction:
    INPUT:
        image - PIL image
        mask - PIL image with corresponding mask
    '''
    fig, axs = plt.subplots(1, 3, figsize=(15,5))

    #plot the original data
    axs[0].imshow(image)
    axs[0].axis('off')
    axs[0].set_title('Image')

    #plot the mask
    axs[1].imshow(mask)
    axs[1].axis('off')
    axs[1].set_title('Mask')

    #plot image and add the mask
    axs[2].imshow(image)
    axs[2].imshow(mask, alpha = 0.5, cmap = "Reds")
    axs[2].axis('off')
    axs[2].set_title('Image with mask overlay')

    # set suptitle
    plt.suptitle(img_name)
    plt.show()


#Find and crop retangle
def find_crop(img, mask, target_size):
  '''
    Function to find contours, create retangle and plot a single prediction:
    INPUT:
        img - PIL image
        mask - PIL image with corresponding mask, mode GRAY
        target_size - tuple like (HEIGHT, WEIGHT)
    RETURN:
        result
    '''
    #Resize
  mask = cv2.resize(mask, target_size)
  img = cv2.resize(img, target_size)

    #Threshold mask
  mask_thresh = cv2.Canny(mask, 127, 255)

    #Find Contours on thresholded mask
  contours = cv2.findContours(mask_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  contours = contours[0] if len(contours) == 2 else contours[1]

    #Draw retangle and crop
  if(len(contours) == 1):
    x, y, w, h = cv2.boundingRect(contours[0])
    cropped_img = img[y:y+400, x:x+1000]
    cropped_mask = mask[y:y+400, x:x+1000]

    result = cv2.bitwise_and(cropped_img, cropped_img, mask=cropped_mask)
    return result
  else:
    print('Image has more than one retangle. Check it again!')
    return False

"""# #Load data ( non augmentation )"""

TRAIN_PATH = '/content/drive/MyDrive/nhập môn AI/KingSalmon/train'
TEST_PATH = '/content/drive/MyDrive/nhập môn AI/KingSalmon/test'
train_parent_folder = next(os.walk(TRAIN_PATH))[1]
test_parent_folder = next(os.walk(TEST_PATH))[1]

#load file train

X_train = []
Y_train = []
train_id = []
print('Getting and resizing train images ... ')
for parent_folder in os.listdir(TRAIN_PATH):
  train_path_child = os.path.join(TRAIN_PATH, parent_folder)
  train_id.append(next(os.walk(train_path_child))[1])
  count = 0
  for child_folder in os.listdir(train_path_child):
    path = os.path.join(train_path_child, child_folder)
    count += 1
    #load image
    # print(path)
    # print(child_folder)
    img = image.load_img(path + '/images/' + child_folder + '.jpg', target_size=(INPUT_HEIGHT, INPUT_WIDTH), color_mode='grayscale')
    img = image.img_to_array(img)
    gamma_corrected = np.array(255*(img / 255) ** 3, dtype = 'uint8')

    _, thresh = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY)
    X_train.append(thresh)

    #load mask
    mask = image.load_img(path + '/masks/' + child_folder + '.jpg', color_mode='grayscale', target_size=(INPUT_HEIGHT, INPUT_WIDTH))
    mask = image.img_to_array(mask)
    Y_train.append(mask)
  print(parent_folder, 'gets', count, 'images')

X_train = np.asarray(X_train).astype('float32')
X_train = X_train / 255.
Y_train = np.asarray(Y_train).astype('float32')
Y_train = Y_train / 255.

np.save('X.npy', X_train)
np.save('Y.npy', Y_train)

# #load file val
# X_val = []
# Y_val = []
# print('Getting and resizing train images ... ')
# for folder in os.listdir(VAL_PATH):
#   path = os.path.join(VAL_PATH, folder)
#   #load image
#   img = image.load_img(path + '/images/' + folder + '.jpg', target_size=(INPUT_HEIGHT, INPUT_WIDTH))
#   img = image.img_to_array(img)
#   X_val.append(img)

#     #load mask
#   mask = image.load_img(path + '/masks/' + folder + '.jpg', color_mode='grayscale', target_size=(INPUT_HEIGHT, INPUT_WIDTH))
#   mask = image.img_to_array(mask)
#   Y_val.append(mask)

# X_val = np.asarray(X_val).astype('float32')
# Y_val = np.asarray(Y_val).astype('float32')
# X_val = X_val / 255.
# Y_val = Y_val / 255.

X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2)

"""**đoạn mã này để .......... load file test**

"""

# Load file test
X_test = []
Y_test = []
test_id = []
print('Getting and resizing train images ... ')
for parent_folder in os.listdir(TEST_PATH):
    test_path_child = os.path.join(TEST_PATH, parent_folder)
    test_id.append(next(os.walk(test_path_child))[1])
    count = 0
    for child_folder in os.listdir(test_path_child):
        path = os.path.join(test_path_child, child_folder)
        count += 1
        # Check if image file exists before loading
        img_path = os.path.join(path, 'images', f'{child_folder}.jpg')
        if not os.path.exists(img_path):
            print(f"Image not found: {img_path}")
            continue

        # Load image
        img = image.load_img(img_path, target_size=(INPUT_HEIGHT, INPUT_WIDTH), color_mode='grayscale')
        img = image.img_to_array(img)
        gamma_corrected = np.array(255 * (img / 255) ** 3, dtype='uint8')

        _, thresh = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY)
        X_test.append(thresh)

        # Load mask
        mask_path = os.path.join(path, 'masks', f'{child_folder}.jpg')
        if not os.path.exists(mask_path):
            print(f"Mask not found: {mask_path}")
            continue

        mask = image.load_img(mask_path, color_mode='grayscale', target_size=(INPUT_HEIGHT, INPUT_WIDTH))
        mask = image.img_to_array(mask)
        Y_test.append(mask)
    print(parent_folder, 'gets', count, 'images')

X_test = np.asarray(X_test).astype('float32')
X_test = X_test / 255.
Y_test = np.asarray(Y_test).astype('float32')
Y_test = Y_train / 255.

#Load file test
X_test= []
Y_test = []
test_id = []
print('Getting and resizing test images ... ')
for parent_folder in os.listdir(TEST_PATH):
  test_path_child = os.path.join(TEST_PATH, parent_folder)
  test_id.append(next(os.walk(test_path_child))[1])
  count = 0
  for child_folder in os.listdir(test_path_child):
    path = os.path.join(test_path_child, child_folder)
    count += 1
    #load image
    img = Image.open(path + '/images/' + child_folder + '.jpg').convert('L')
    img = img.resize((INPUT_WIDTH, INPUT_HEIGHT))
    img_array = np.array(img)
    gamma_corrected = np.array(255*(img_array/ 255) ** 3, dtype = 'uint8')

    _, thresh = cv2.threshold(img_array, 150, 255, cv2.THRESH_BINARY)
    X_test.append(thresh)

    #load mask
    mask = Image.open(path + '/images/' + child_folder + '.jpg').convert('L')
    mask = mask.resize((INPUT_WIDTH, INPUT_HEIGHT))
    mask = np.array(mask)
    Y_test.append(mask)
  print(parent_folder, 'gets', count, 'images')

X_test = np.asarray(X_test).astype('float32')
X_test = X_test / 255.
Y_test = np.asarray(Y_test).astype('float32')
Y_test = Y_test / 255.

# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)
#Thiếu 3 ảnh 67, 99 272 trong tập OC171D
print(X_test.shape)
print(X_train.shape)
print(Y_train.shape)
print(X_val.shape)
print(Y_val.shape)

"""#Model"""

model = UNet()
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["acc"])
model.summary()

"""#Training"""

# Initialize our callbacks
# This will save the best weights only
checkpoint = ModelCheckpoint('/content/drive/MyDrive/Project20202/Segmentation/model.h5',
                             monitor="val_loss",
                             mode="min",
                             save_best_only = True,
                             verbose=1)
# It will stop training if validation accuracy doesn't improve
earlystop = EarlyStopping(monitor = 'val_loss',
                          min_delta = 0,
                          patience = 5,
                          verbose = 1,
                          restore_best_weights = True)

# model = load_model('/content/drive/MyDrive/best_model(0.0071).h5')
# Fit our model
results = model.fit(X_train, Y_train,
                    validation_data = (X_val, Y_val),
                    epochs=5, batch_size=32,
                    callbacks=[checkpoint, earlystop],
                    verbose=1)

"""#Predict on test set"""

model = load_model('/content/drive/MyDrive/Project20202/Segmentation/model.h5')
preds_test = model.predict(X_test, verbose=1, batch_size=16)
# Thresholding
preds_test_t = (preds_test > 0.5).astype(np.uint8)

# Đường dẫn đến thư mục "masks"
output_folder = "/content/drive/MyDrive/dataset/Copy of KingSalmon/masks"

# Tạo thư mục nếu nó chưa tồn tại
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

#Show predicted mask
count = 0
for i in range(len(test_id)):
  for j in range(len(test_id[i])):
    # img_name = str(test_parent_folder[i] + '/' + test_id[i][j])
    img_name = 'chien_test_mask_' + str(j) # Đổi tên tệp theo nhu cầu của bạn
    img = X_test[count]
    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    # mask = cv2.cvtColor(preds_test_t[count], cv2.COLOR_GRAY2RGB)
    mask = np.squeeze(preds_test_t[count])
    mask *= 255
    mask_path = os.path.join(output_folder, f"{img_name}.jpg")
    cv2.imwrite(mask_path, mask)
    plot_image_and_mask(img, mask, img_name)
    count += 1
  plt.show()

# Đường dẫn đến thư mục "masks"
output_folder = "/content/drive/MyDrive/dataset/Copy of KingSalmon/masks"

# Tạo thư mục nếu nó chưa tồn tại
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

count = 0
for i in range(len(test_id)):
    for j in range(len(test_id[i])):
        img_name = 'chien_test_mask_' + str(j) # Đổi tên tệp theo nhu cầu của bạn
        mask = np.squeeze(preds_test_t[count])
        mask *= 255  # Đảm bảo giá trị pixel trong khoảng từ 0 đến 255
        mask = mask.astype(np.uint8)
        mask_path = os.path.join(output_folder, f"{img_name}.jpg")
        cv2.imwrite(mask_path, mask)
        count += 1

count

count = 0
for i in range(len(test_id)):
    for j in range(len(test_id[i])):
        img_name = str(parent_folder + '/' + test_id[i][j])  # Sử dụng parent_folder ở đây
        img = X_test[count]
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
        # mask = cv2.cvtColor(preds_test_t[count], cv2.COLOR_GRAY2RGB)
        mask = np.squeeze(preds_test_t[count])
        plot_image_and_mask(img, mask, img_name)
        count += 1
    plt.show()

count

# #Show predicted mask
# count = 0
# for i in range(len(test_id)):
#   for j in range(len(test_id[i])):
#     img_name = str(test_parent_folder[i] + '/' + test_id[i][j])
#     img = X_test[count]
#     img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
#     # mask = cv2.cvtColor(preds_test_t[count], cv2.COLOR_GRAY2RGB)
#     mask = np.squeeze(preds_test_t[count])
#     plot_image_and_mask(img, mask, img_name)
#     count += 1
#   plt.show()

"""#Create folder and save mask for each image of test set"""

# Create masks folder for each image

for parent_folder in os.listdir(TEST_PATH):
  child_path = os.path.join(TEST_PATH, parent_folder)
  for folder in os.listdir(child_path):
    path = os.path.join(child_path, folder)
    mask_folder = os.path.join(path, 'masks')
    if os.path.exists(mask_folder) == False:
      os.mkdir(mask_folder)
      print(mask_folder)

from PIL import Image
import numpy as np

# Ví dụ: chọn một mảng từ preds_test_t (ở đây mình chọn mảng đầu tiên)
selected_array = preds_test_t[0]

# Chuyển đổi mảng thành kiểu dữ liệu uint8 và tạo hình ảnh xám
gray_array = (np.mean(selected_array, axis=-1) * 255).astype(np.uint8)
created_mask = Image.fromarray(gray_array, mode='L')

# Lưu hình ảnh hoặc thực hiện các thao tác khác với created_mask

count = 0
test_parent_folder = ["OC171B", "OC171C3", "OC171D", "OC171A"]
for i in range(len(test_parent_folder)):
    parent_path = os.path.join(TEST_PATH, test_parent_folder[i])
    for j in range(len(test_id[i])):
        mask_folder = parent_path + '/' + test_id[i][j] + '/masks/'

        # Kiểm tra xem thư mục tồn tại trước khi truy cập
        if os.path.exists(mask_folder):
            for folder_name in os.listdir(mask_folder):
                file_path = os.path.join(mask_folder, folder_name)
                if os.path.isfile(file_path):
                    os.remove(file_path)
        else:
            print(f"Mask folder '{mask_folder}' does not exist.")

        count += 1

# Save masks
count = 0
test_parent_folder = ["OC171B", "OC171C3", "OC171D", "OC171A"]
for i in range(len(test_parent_folder)):
    parent_path = os.path.join(TEST_PATH, test_parent_folder[i])
    for j in range(len(test_id[i])):
        mask_folder = os.path.join(parent_path, test_id[i][j], 'masks')
        os.makedirs(mask_folder, exist_ok=True)  # Tạo thư mục nếu nó không tồn tại
        mask_name = os.path.join(mask_folder, test_id[i][j] + '.jpg')

        # Tạo mặt nạ từ preds_test_t[count] và lưu vào mask_name
        array_to_convert = preds_test_t[count].astype(np.float32) / 255.0
        image_array = preds_test_t[count].squeeze()
        created_mask = Image.fromarray(image_array.astype('uint8'), mode='L')
        created_mask.save(mask_name)

        count += 1

# # Save masks
# count = 0
# for i in range(len(test_parent_folder)):
#   parent_path = os.path.join(TEST_PATH, test_parent_folder[i])
#   for j in range(len(test_id[i])):
#     mask_name = parent_path + '/' + test_id[i][j] + '/masks/' + test_id[i][j] + '.jpg'
#     created_mask = image.array_to_img(preds_test_t[count])
#     created_mask.save(mask_name)
#     count += 1
#     # print(mask_name)

# print('Created ' + count + ' masks')

"""#Cropped images from train set"""

# Draft

img = cv2.imread('/content/drive/MyDrive/dataset/KingSalmon-20230823T131007Z-001/KingSalmon/train/OC171A/156/images/156.jpg')
mask = cv2.imread('/content/drive/MyDrive/dataset/KingSalmon-20230823T131007Z-001/KingSalmon/train/OC171A/156/masks/156.jpg')
mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)

cropped_image = find_crop(img, mask, (1024,1024))
plt.imshow(cropped_image)
plt.suptitle('OC171A/156')
plt.show()

#Draft

img = cv2.imread('/content/drive/MyDrive/dataset/KingSalmon-20230823T131007Z-001/KingSalmon/train/OC171A/156/images/156.jpg')
mask = cv2.imread('/content/drive/MyDrive/dataset/KingSalmon-20230823T131007Z-001/KingSalmon/train/OC171A/156/masks/156.jpg')
mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)

target_size = (1024, 1024)

    #Resize
mask = cv2.resize(mask, target_size)
img = cv2.resize(img, target_size)

    #Threshold mask
mask_thresh = cv2.Canny(mask, 127, 255)

    #Find Contours on thresholded mask
contours = cv2.findContours(mask_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
contours = contours[0] if len(contours) == 2 else contours[1]

if(len(contours) == 1):
  x, y, w, h = cv2.boundingRect(contours[0])
  cropped_img = img[y:y+400, x:x+1000]
  cropped_mask = mask[y:y+400, x:x+1000]

test = cv2.bitwise_and(cropped_img, cropped_img, mask=cropped_mask)

plt.imshow(test)
plt.show()
print(test.shape)

try:
  target_size = (1024, 1024)
  DATASET_20202 = '/content/drive/MyDrive/dataset/KingSalmon-20230823T131007Z-001/KingSalmon/train'
  for parent_folder in os.listdir(TRAIN_PATH):
    parent_path = os.path.join(TRAIN_PATH, parent_folder)
    parent_crop_img_path = os.path.join(DATASET_20202, parent_folder)
    for child_folder in os.listdir(parent_path):
      path = os.path.join(parent_path, child_folder)
      crop_img_path = parent_crop_img_path + '/' + child_folder + '.jpg'

      #Load Mask
      mask = cv2.imread(path  + '/masks/' + child_folder + '.jpg')
      mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)

      #Load image
      img = cv2.imread(path  + '/images/' + child_folder + '.jpg')
      name = parent_folder + '/' + child_folder

      #Crop image
      cropped_image = find_crop(img, mask, target_size)
      # plt.imshow(cropped_image)
      # plt.show()

      #Save cropped images
      cropped_image = image.array_to_img(cropped_image)
      cropped_image.save(crop_img_path)
    print(parent_folder + ' saved ' + str(len(os.listdir(parent_path))) + ' new images')
except:
  print(child_folder)

"""#Preprocessing for classification"""

dfa = pd.read_excel('/content/drive/MyDrive/nhập môn AI/KingSalmon/X-ray scoring NZKS OT high fish oil trial Score Data OC171A.xlsx', skiprows=(1,2,3))

temp_data_a = dfa[['LKS Region 1 X-ray', 'LKS Region 2 X-ray', 'LKS Region 3 X-ray', 'LKS Region 4 X-ray',
                'Fusion Region 1 X-ray', 'Fusion Region 2 X-ray', 'Fusion Region 3 X-ray', 'Fusion Region 1 X-ray',
                'Compression and/or reduced intervertebral space Region 1 X-ray',
                'Compression and/or reduced intervertebral space Region 2 X-ray',
                'Compression and/or reduced intervertebral space Region 3 X-ray',
                'Compression and/or reduced intervertebral space Region 4 X-ray',
                'Vertical shift Region 1 X-ray',
                'Vertical shift Region 2 X-ray',
                'Vertical shift Region 3 X-ray',
                'Vertical shift Region 4 X-ray'
                ]]
#Positive
po_a = temp_data_a.max(axis = 1)
number_of_images = len(po_a)
for i in range(number_of_images):
  if po_a[i] > 0:
    po_a[i] = 1
#Gắn thêm cột positive bằng po_a
dfa['positive'] = po_a
dfa.head(10)

dfb = pd.read_excel('/content/drive/MyDrive/nhập môn AI/KingSalmon/X-ray scoring NZKS OT high fish oil trial Score Data OC171B.xlsx', skiprows=(1,2,3))

temp_data_b = dfb[['LKS Region 1 X-ray', 'LKS Region 2 X-ray', 'LKS Region 3 X-ray', 'LKS Region 4 X-ray',
                'Fusion Region 1 X-ray', 'Fusion Region 2 X-ray', 'Fusion Region 3 X-ray', 'Fusion Region 1 X-ray',
                'Compression and/or reduced intervertebral space Region 1 X-ray',
                'Compression and/or reduced intervertebral space Region 2 X-ray',
                'Compression and/or reduced intervertebral space Region 3 X-ray',
                'Compression and/or reduced intervertebral space Region 4 X-ray',
                'Vertical shift Region 1 X-ray', 'Vertical shift Region 2 X-ray', 'Vertical shift Region 3 X-ray', 'Vertical shift Region 4 X-ray'
                ]]
#Positive
po_b = temp_data_b.max(axis = 1)
number_of_images_b = len(po_b)
for i in range(number_of_images_b):
  if po_b[i] > 0:
    po_b[i] = 1

dfb['positive'] = po_b

dfc3 = pd.read_excel('/content/drive/MyDrive/nhập môn AI/KingSalmon/X-ray scoring NZKS OT high fish oil trial Score Data OC171C3.xlsx', skiprows=(1,2,3))

temp_data_c3 = dfc3[['LKS Region 1 X-ray', 'LKS Region 2 X-ray', 'LKS Region 3 X-ray', 'LKS Region 4 X-ray',
                'Fusion Region 1 X-ray', 'Fusion Region 2 X-ray', 'Fusion Region 3 X-ray', 'Fusion Region 1 X-ray',
                'Compression and/or reduced intervertebral space Region 1 X-ray',
                'Compression and/or reduced intervertebral space Region 2 X-ray',
                'Compression and/or reduced intervertebral space Region 3 X-ray',
                'Compression and/or reduced intervertebral space Region 4 X-ray',
                'Vertical shift Region 1 X-ray', 'Vertical shift Region 2 X-ray', 'Vertical shift Region 3 X-ray', 'Vertical shift Region 4 X-ray'
                ]]
#Positive
po_c3 = temp_data_c3.max(axis = 1)
number_of_images_c3 = len(po_c3)
for i in range(number_of_images_c3):
  if po_c3[i] > 0:
    po_c3[i] = 1


#Thêm vào bảng
dfc3['positive'] = po_c3

dfd = pd.read_excel('/content/drive/MyDrive/nhập môn AI/KingSalmon/X-ray scoring NZKS OT high fish oil trial Score Data OC171D.xlsx', skiprows=(1,2,3))

temp_data_d = dfd[['LKS Region 1 X-ray', 'LKS Region 2 X-ray', 'LKS Region 3 X-ray', 'LKS Region 4 X-ray',
                'Fusion Region 1 X-ray', 'Fusion Region 2 X-ray', 'Fusion Region 3 X-ray', 'Fusion Region 1 X-ray',
                'Compression and/or reduced intervertebral space Region 1 X-ray',
                'Compression and/or reduced intervertebral space Region 2 X-ray',
                'Compression and/or reduced intervertebral space Region 3 X-ray',
                'Compression and/or reduced intervertebral space Region 4 X-ray',
                'Vertical shift Region 1 X-ray', 'Vertical shift Region 2 X-ray', 'Vertical shift Region 3 X-ray', 'Vertical shift Region 4 X-ray'
                ]]
#Positive
po_d = temp_data_d.max(axis = 1)
number_of_images_d = len(po_d)
for i in range(number_of_images_d):
  if po_d[i] > 0:
    po_d[i] = 1


#Thêm vào bảng
dfd['positive'] = po_d

#Gắn vào dataframe mới
df = pd.DataFrame()
df = df.append(dfa)
df = df.append(dfb)
df = df.append(dfc3)
df = df.append(dfd)
print(df)

#save file label mới cho bài toán phân loại
df.to_excel('/content/drive/MyDrive/nhập môn AI/KingSalmon/OC171.xlsx', index=False)

df = pd.read_excel('/content/drive/MyDrive/nhập môn AI/KingSalmon/OC171.xlsx')
df

temp_df = df[['Unnamed: 0', 'positive']]
temp_df.rename(columns={'Unnamed: 0':'Name'}, inplace=True)
temp_df

name = temp_df.Name.values
positive = temp_df.positive.values

for i in range(len(name)):
  name[i] = name[i] + '.jpg'
temp_df

OLD_PATH = '/content/drive/MyDrive/nhập môn AI/KingSalmon/dataset'
NEW_PATH = '/content/drive/MyDrive/nhập môn AI/KingSalmon/classify'

for i in range(len(name)):
  curr_path = OLD_PATH + name[i]
  new_name = name[i].replace('/', '_')
  if os.path.exists(curr_path):
    if positive[i] == 1:
      new_path = NEW_PATH + 'positive/' + new_name
    else:
      new_path = NEW_PATH + 'negative/' + new_name
    os.renames(curr_path, new_path)
  else:
    print(curr_path, 'is not existed.')

temp = next(os.walk('/content/drive/MyDrive/nhập môn AI/KingSalmon/classify/negative'))[1]
D:\cao\project_20223_(256x256)_checkpoint.py